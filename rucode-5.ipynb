{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9415087,"sourceType":"datasetVersion","datasetId":5717830},{"sourceId":9421682,"sourceType":"datasetVersion","datasetId":5722685}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-17T19:47:20.437668Z","iopub.execute_input":"2024-09-17T19:47:20.438049Z","iopub.status.idle":"2024-09-17T19:47:21.498037Z","shell.execute_reply.started":"2024-09-17T19:47:20.438004Z","shell.execute_reply":"2024-09-17T19:47:21.497158Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport numpy as np\nimport timm\nfrom torch.optim import Adam\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import models, transforms\nfrom sklearn.model_selection import train_test_split\nfrom PIL import Image\nfrom tqdm import tqdm\nfrom transformers import ViTImageProcessor, ViTModel\nfrom albumentations import (HorizontalFlip, RandomBrightnessContrast, ShiftScaleRotate, \n                            Resize, Compose, Normalize)\nfrom albumentations.pytorch import ToTensorV2\n","metadata":{"execution":{"iopub.status.busy":"2024-09-17T19:47:28.017240Z","iopub.execute_input":"2024-09-17T19:47:28.017739Z","iopub.status.idle":"2024-09-17T19:47:48.414707Z","shell.execute_reply.started":"2024-09-17T19:47:28.017701Z","shell.execute_reply":"2024-09-17T19:47:48.413740Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install pillow-avif-plugin","metadata":{"execution":{"iopub.status.busy":"2024-09-17T19:47:48.416305Z","iopub.execute_input":"2024-09-17T19:47:48.416867Z","iopub.status.idle":"2024-09-17T19:48:05.003498Z","shell.execute_reply.started":"2024-09-17T19:47:48.416833Z","shell.execute_reply":"2024-09-17T19:48:05.002294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pillow_avif","metadata":{"execution":{"iopub.status.busy":"2024-09-17T19:48:05.005470Z","iopub.execute_input":"2024-09-17T19:48:05.006408Z","iopub.status.idle":"2024-09-17T19:48:05.020910Z","shell.execute_reply.started":"2024-09-17T19:48:05.006356Z","shell.execute_reply":"2024-09-17T19:48:05.020120Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_train_augmentations():\n    return Compose([\n        Resize(224, 224),  # Размер изображений под модель\n        HorizontalFlip(p=0.5),  # Отражение изображений с вероятностью 50%\n        RandomBrightnessContrast(p=0.2),  # Изменение яркости и контрастности\n        ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5),  # Сдвиг, масштабирование и поворот\n        Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),  # Нормализация по стандарту ImageNet\n        ToTensorV2()  # Преобразование в тензор\n    ])\n\ndef get_valid_augmentations():\n    return Compose([\n        Resize(224, 224),  # Изменение размера изображений\n        Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n        ToTensorV2()\n    ])","metadata":{"execution":{"iopub.status.busy":"2024-09-17T19:48:59.903938Z","iopub.execute_input":"2024-09-17T19:48:59.904878Z","iopub.status.idle":"2024-09-17T19:48:59.912102Z","shell.execute_reply.started":"2024-09-17T19:48:59.904835Z","shell.execute_reply":"2024-09-17T19:48:59.910999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ImageDataset(torch.utils.data.Dataset):\n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.image_paths = []\n        self.labels = []\n\n        # Проходим по всем классам (папкам)\n        for class_name in sorted(os.listdir(root_dir)):\n            class_dir = os.path.join(root_dir, class_name)\n            if os.path.isdir(class_dir):\n                class_index = int(class_name) - 1  # Преобразуем имя папки в индекс (0-based)\n                for image_name in os.listdir(class_dir):\n                    image_path = os.path.join(class_dir, image_name)\n                    if os.path.isfile(image_path):\n                        self.image_paths.append(image_path)\n                        self.labels.append(class_index)\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        image_path = self.image_paths[idx]\n        label = self.labels[idx]\n        image = Image.open(image_path).convert(\"RGB\")\n        image = np.array(image)  # Преобразуем в numpy массив\n\n        if self.transform:\n            # Применяем трансформации\n            augmented = self.transform(image=image)\n            image = augmented['image']\n\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2024-09-17T19:48:05.031885Z","iopub.execute_input":"2024-09-17T19:48:05.032193Z","iopub.status.idle":"2024-09-17T19:48:05.042967Z","shell.execute_reply.started":"2024-09-17T19:48:05.032162Z","shell.execute_reply":"2024-09-17T19:48:05.042140Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TestImageDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.image_paths = []\n\n        # Проходим по всем файлам в корневой директории\n        for image_name in os.listdir(root_dir):\n            image_path = os.path.join(root_dir, image_name)\n            if os.path.isfile(image_path):\n                self.image_paths.append(image_path)\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        image_path = self.image_paths[idx]\n        image = Image.open(image_path).convert(\"RGB\")\n        image = np.array(image)  # Преобразуем в numpy массив\n\n        # Извлекаем название файла\n        file_name = os.path.basename(image_path)\n\n        if self.transform:\n            # Применяем трансформации\n            augmented = self.transform(image=image)\n            image = augmented['image']\n\n        return image, file_name","metadata":{"execution":{"iopub.status.busy":"2024-09-17T19:48:05.044035Z","iopub.execute_input":"2024-09-17T19:48:05.044367Z","iopub.status.idle":"2024-09-17T19:48:05.054151Z","shell.execute_reply.started":"2024-09-17T19:48:05.044336Z","shell.execute_reply":"2024-09-17T19:48:05.053379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_dataloader(data_dir, batch_size=8, train_transforms=None,shuffle = True):\n    train_dataset = ImageDataset(root_dir=data_dir, transform=train_transforms)\n\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n\n    return train_loader","metadata":{"execution":{"iopub.status.busy":"2024-09-17T19:48:05.055255Z","iopub.execute_input":"2024-09-17T19:48:05.055544Z","iopub.status.idle":"2024-09-17T19:48:05.064943Z","shell.execute_reply.started":"2024-09-17T19:48:05.055514Z","shell.execute_reply":"2024-09-17T19:48:05.064139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Директория с данными (где хранятся изображения для всех классов)\ndata_dir = \"/kaggle/input/training/rucode\"\n\n# Параметры\nbatch_size = 16\n\n# Аугментации\ntrain_transforms = get_train_augmentations()\n\n# Создание загрузчика данных для обучения\ntrain_loader = create_dataloader(data_dir, batch_size, train_transforms)\n\n# Пример того, как итерировать по данным\nfor images, labels in train_loader:\n    print(images.shape, labels.shape)\n    print(labels)\n    break  # Для теста выводим один батч","metadata":{"execution":{"iopub.status.busy":"2024-09-17T19:49:05.866917Z","iopub.execute_input":"2024-09-17T19:49:05.867673Z","iopub.status.idle":"2024-09-17T19:49:07.541018Z","shell.execute_reply.started":"2024-09-17T19:49:05.867631Z","shell.execute_reply":"2024-09-17T19:49:07.539939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Пример того, как итерировать по данным\nfor images, labels in train_loader:\n    print(images.shape, labels.shape)\n    print(labels)\n    print(images[1].shape)\n    break  # Для теста выводим один батч","metadata":{"execution":{"iopub.status.busy":"2024-09-17T19:48:06.915064Z","iopub.execute_input":"2024-09-17T19:48:06.915584Z","iopub.status.idle":"2024-09-17T19:48:07.230220Z","shell.execute_reply.started":"2024-09-17T19:48:06.915535Z","shell.execute_reply":"2024-09-17T19:48:07.229139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2024-09-17T19:40:02.762277Z","iopub.execute_input":"2024-09-17T19:40:02.762691Z","iopub.status.idle":"2024-09-17T19:40:02.767222Z","shell.execute_reply.started":"2024-09-17T19:40:02.762649Z","shell.execute_reply":"2024-09-17T19:40:02.766274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tensor_image = images[6]\n\n# Убедимся, что это тензор на CPU и преобразуем его в numpy\nnumpy_image = tensor_image.permute(1, 2, 0).cpu().numpy()\n\n# Если изображение было нормализовано, то нужно денормализовать его:\n# Например, если использовались средние и стандартные отклонения для нормализации:\nmean = [0.485, 0.456, 0.406]\nstd = [0.229, 0.224, 0.225]\n# denormalize:\nnumpy_image = numpy_image * std + mean\n\n# Преобразуем значения из диапазона [0, 1] в [0, 255], если они нормализованы\nnumpy_image = (numpy_image * 255).astype(np.uint8)\n\n# Преобразуем numpy массив обратно в изображение с помощью PIL\nimage = Image.fromarray(numpy_image)\n\nprint(labels[6])\nplt.imshow(image)\nplt.axis('off')  # Не показывать оси\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-17T19:03:26.525097Z","iopub.execute_input":"2024-09-17T19:03:26.525855Z","iopub.status.idle":"2024-09-17T19:03:26.742435Z","shell.execute_reply.started":"2024-09-17T19:03:26.525814Z","shell.execute_reply":"2024-09-17T19:03:26.741502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-09-17T19:48:07.233002Z","iopub.execute_input":"2024-09-17T19:48:07.233347Z","iopub.status.idle":"2024-09-17T19:48:07.246603Z","shell.execute_reply.started":"2024-09-17T19:48:07.233310Z","shell.execute_reply":"2024-09-17T19:48:07.245730Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-09-17T19:48:07.247684Z","iopub.execute_input":"2024-09-17T19:48:07.247971Z","iopub.status.idle":"2024-09-17T19:48:07.278590Z","shell.execute_reply.started":"2024-09-17T19:48:07.247939Z","shell.execute_reply":"2024-09-17T19:48:07.277601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SimpleNN(nn.Module):\n    def __init__(self):\n        super(SimpleNN, self).__init__()\n        self.vit = timm.create_model('vit_base_patch8_224.augreg2_in21k_ft_in1k', pretrained=True)\n        \n        # Полносвязные слои с BatchNorm и Dropout\n        self.fc1 = nn.Linear(1000, 512)\n        self.bn1 = nn.BatchNorm1d(512)\n        self.dropout1 = nn.Dropout(0.3)\n\n        self.fc2 = nn.Linear(512, 256)\n        self.bn2 = nn.BatchNorm1d(256)\n        self.dropout2 = nn.Dropout(0.2)\n\n        self.fc3 = nn.Linear(256, 128)\n        self.bn3 = nn.BatchNorm1d(128)\n        self.dropout3 = nn.Dropout(0.1)\n\n        self.fc4 = nn.Linear(128, 16)   # Выходной слой для 16 классов\n\n        self.relu = nn.ReLU()\n        \n        # Разморозка последних двух слоев ViT\n        self._unfreeze_last_two_layers()\n\n    def forward(self, x):\n        # Проход через Vision Transformer\n        output = self.vit(x)\n\n        # Полносвязные слои с BatchNorm, Dropout и ReLU\n        output = self.fc1(output)\n        output = self.bn1(output)\n        output = self.relu(output)\n        output = self.dropout1(output)\n\n        output = self.fc2(output)\n        output = self.bn2(output)\n        output = self.relu(output)\n        output = self.dropout2(output)\n\n        output = self.fc3(output)\n        output = self.bn3(output)\n        output = self.relu(output)\n        output = self.dropout3(output)\n\n        output = self.fc4(output)\n        output = F.softmax(output, dim=-1)\n\n        return output\n    \n    def _unfreeze_last_two_layers(self):\n        # Разморозка всех слоев\n        for param in self.vit.parameters():\n            param.requires_grad = False\n        \n        # Разморозка последних двух слоев\n        # Путь к слоям может отличаться в зависимости от версии и типа модели ViT\n        # Проверьте правильные имена параметров, если это не сработает\n\n        for name, param in self.vit.named_parameters():\n            if 'blocks.10.' in name or 'blocks.11.' in name:  # Последние два слоя могут отличаться\n                param.requires_grad = True","metadata":{"execution":{"iopub.status.busy":"2024-09-17T19:48:08.920155Z","iopub.execute_input":"2024-09-17T19:48:08.920546Z","iopub.status.idle":"2024-09-17T19:48:08.933230Z","shell.execute_reply.started":"2024-09-17T19:48:08.920507Z","shell.execute_reply":"2024-09-17T19:48:08.932312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = SimpleNN()","metadata":{"execution":{"iopub.status.busy":"2024-09-17T19:48:13.859989Z","iopub.execute_input":"2024-09-17T19:48:13.860859Z","iopub.status.idle":"2024-09-17T19:48:23.834408Z","shell.execute_reply.started":"2024-09-17T19:48:13.860817Z","shell.execute_reply":"2024-09-17T19:48:23.833471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-09-17T19:48:23.835896Z","iopub.execute_input":"2024-09-17T19:48:23.836231Z","iopub.status.idle":"2024-09-17T19:48:24.102128Z","shell.execute_reply.started":"2024-09-17T19:48:23.836192Z","shell.execute_reply":"2024-09-17T19:48:24.101134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = Adam(model.parameters(), lr=0.01)","metadata":{"execution":{"iopub.status.busy":"2024-09-17T19:48:28.509370Z","iopub.execute_input":"2024-09-17T19:48:28.509762Z","iopub.status.idle":"2024-09-17T19:48:28.515914Z","shell.execute_reply.started":"2024-09-17T19:48:28.509723Z","shell.execute_reply":"2024-09-17T19:48:28.514923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score","metadata":{"execution":{"iopub.status.busy":"2024-09-17T19:48:30.931270Z","iopub.execute_input":"2024-09-17T19:48:30.931650Z","iopub.status.idle":"2024-09-17T19:48:30.936324Z","shell.execute_reply.started":"2024-09-17T19:48:30.931611Z","shell.execute_reply":"2024-09-17T19:48:30.935139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model, train_loader, criterion, optimizer, device, num_epochs=20):\n    model.train()  # Переводим модель в режим обучения\n\n    for epoch in range(num_epochs):\n        running_loss = 0.0\n        correct = 0\n        total = 0\n        all_labels = []\n        all_predictions = []\n\n        # Проходим по батчам\n        for images, labels in tqdm(train_loader):\n            images, labels = images.to(device), labels.to(device)\n\n            # Обнуление градиентов\n            optimizer.zero_grad()\n\n            # Прямой проход (forward pass)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n            # Обратный проход (backward pass) и обновление весов\n            loss.backward()\n            optimizer.step()\n\n            # Статистика\n            running_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n\n            # Собираем все метки и предсказания\n            all_labels.extend(labels.cpu().numpy())\n            all_predictions.extend(predicted.cpu().numpy())\n\n        # Вычисляем F1-Score\n        f1_macro = f1_score(all_labels, all_predictions, average='macro')\n\n        # Выводим статистику за эпоху\n        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {100 * correct / total:.2f}%, F1-Score (macro): {f1_macro:.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-09-17T19:48:32.059479Z","iopub.execute_input":"2024-09-17T19:48:32.060345Z","iopub.status.idle":"2024-09-17T19:48:32.069563Z","shell.execute_reply.started":"2024-09-17T19:48:32.060304Z","shell.execute_reply":"2024-09-17T19:48:32.068493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_model(model, train_loader, criterion, optimizer, device, num_epochs=100)","metadata":{"execution":{"iopub.status.busy":"2024-09-17T19:49:14.722259Z","iopub.execute_input":"2024-09-17T19:49:14.723125Z","iopub.status.idle":"2024-09-17T19:50:28.381183Z","shell.execute_reply.started":"2024-09-17T19:49:14.723067Z","shell.execute_reply":"2024-09-17T19:50:28.380293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dir = '/kaggle/input/testoublic/public_test'","metadata":{"execution":{"iopub.status.busy":"2024-09-17T19:50:50.343984Z","iopub.execute_input":"2024-09-17T19:50:50.344996Z","iopub.status.idle":"2024-09-17T19:50:50.349234Z","shell.execute_reply.started":"2024-09-17T19:50:50.344953Z","shell.execute_reply":"2024-09-17T19:50:50.348151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_aug = get_valid_augmentations()","metadata":{"execution":{"iopub.status.busy":"2024-09-17T19:50:51.781070Z","iopub.execute_input":"2024-09-17T19:50:51.781485Z","iopub.status.idle":"2024-09-17T19:50:51.786485Z","shell.execute_reply.started":"2024-09-17T19:50:51.781445Z","shell.execute_reply":"2024-09-17T19:50:51.785573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset =TestImageDataset(root_dir=test_dir,transform = test_aug)","metadata":{"execution":{"iopub.status.busy":"2024-09-17T19:50:53.128504Z","iopub.execute_input":"2024-09-17T19:50:53.128855Z","iopub.status.idle":"2024-09-17T19:50:54.181919Z","shell.execute_reply.started":"2024-09-17T19:50:53.128822Z","shell.execute_reply":"2024-09-17T19:50:54.181107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Пример того, как итерировать по данным\nfor images in tqdm(test_dataset):\n    print(images)\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2024-09-17T19:50:55.924697Z","iopub.execute_input":"2024-09-17T19:50:55.925589Z","iopub.status.idle":"2024-09-17T19:51:00.015928Z","shell.execute_reply.started":"2024-09-17T19:50:55.925545Z","shell.execute_reply":"2024-09-17T19:51:00.014591Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_and_collect(model, test_dataset, device, batch_size=16):\n    model.eval()  # Переключаем модель в режим оценки\n    predictions = []\n    image_names = []\n    \n    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n    \n    with torch.no_grad():\n        for images, paths in test_loader:\n            images = images.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs, dim=1)\n            \n            # Преобразуем предсказания в список и собираем пути изображений\n            predictions.extend(predicted.cpu().numpy() + 1)\n            image_names.extend(paths)\n    \n    # Создаем DataFrame\n    df = pd.DataFrame({\n        'image_name': image_names,\n        'class_number': predictions\n    })\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2024-09-17T19:51:01.939817Z","iopub.execute_input":"2024-09-17T19:51:01.940229Z","iopub.status.idle":"2024-09-17T19:51:01.947551Z","shell.execute_reply.started":"2024-09-17T19:51:01.940186Z","shell.execute_reply":"2024-09-17T19:51:01.946586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_predictions = predict_and_collect(model, test_dataset, device)","metadata":{"execution":{"iopub.status.busy":"2024-09-17T19:51:05.761332Z","iopub.execute_input":"2024-09-17T19:51:05.761725Z","iopub.status.idle":"2024-09-17T19:51:45.805596Z","shell.execute_reply.started":"2024-09-17T19:51:05.761689Z","shell.execute_reply":"2024-09-17T19:51:45.804497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_predictions","metadata":{"execution":{"iopub.status.busy":"2024-09-17T19:51:45.807624Z","iopub.execute_input":"2024-09-17T19:51:45.808114Z","iopub.status.idle":"2024-09-17T19:51:45.831959Z","shell.execute_reply.started":"2024-09-17T19:51:45.808051Z","shell.execute_reply":"2024-09-17T19:51:45.831116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_predictions.to_csv('100_epoch_seed_732.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-17T19:51:59.214925Z","iopub.execute_input":"2024-09-17T19:51:59.215695Z","iopub.status.idle":"2024-09-17T19:51:59.225460Z","shell.execute_reply.started":"2024-09-17T19:51:59.215651Z","shell.execute_reply":"2024-09-17T19:51:59.224526Z"},"trusted":true},"execution_count":null,"outputs":[]}]}